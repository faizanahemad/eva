{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/faizanahemad/eva/blob/master/assignment-14/DavidNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OyHnQWenZ1aq"
   },
   "source": [
    "**List of Changes**\n",
    "\n",
    "- Apply OLR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kOsYqWHvQBrZ",
    "outputId": "5d7a74d9-2781-44da-88d0-ab8674930c5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time, math\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcVY1UhnQPDO"
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LfLeMAyQU7z"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512 #@param {type:\"integer\"}\n",
    "MOMENTUM = 0.9 #@param {type:\"number\"}\n",
    "LEARNING_RATE = 0.4 #@param {type:\"number\"}\n",
    "WEIGHT_DECAY = 5e-4 #@param {type:\"number\"}\n",
    "EPOCHS = 24 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EQC9BguoQcfp"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "len_train, len_test = len(x_train), len(x_test)\n",
    "y_train = y_train.astype('int64').reshape(len_train)\n",
    "y_test = y_test.astype('int64').reshape(len_test)\n",
    "\n",
    "train_mean = np.mean(x_train, axis=(0,1,2))\n",
    "train_std = np.std(x_train, axis=(0,1,2))\n",
    "\n",
    "normalize = lambda x: ((x - train_mean) / train_std).astype('float32') # todo: check here\n",
    "pad4 = lambda x: np.pad(x, [(0, 0), (4, 4), (4, 4), (0, 0)], mode='reflect')\n",
    "\n",
    "x_train = normalize(pad4(x_train))\n",
    "x_test = normalize(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AwS9BRv_QWR0"
   },
   "outputs": [],
   "source": [
    "def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
    "    fan = np.prod(shape[:-1])\n",
    "    bound = 1 / (math.sqrt(fan))\n",
    "    return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=dtype)\n",
    "\n",
    "def init_pytorch(shape, dtype=tf.float32, partition_info=None):\n",
    "    fan = np.prod(shape[:-1])\n",
    "    bound = 0.5 / (math.sqrt(fan))\n",
    "    return tf.random.truncated_normal(shape, mean=0,stddev=bound)\n",
    "\n",
    "\n",
    "class ConvBN(tf.keras.Model):\n",
    "    def __init__(self, c_out):\n",
    "        super().__init__()\n",
    "        self.conv = tf.keras.layers.Conv2D(filters=c_out, kernel_size=3, padding=\"SAME\", kernel_initializer=init_pytorch, use_bias=False)\n",
    "        self.bn = tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.relu(self.bn(self.conv(inputs)))\n",
    "\n",
    "    \n",
    "    \n",
    "class ResBlk(tf.keras.Model):\n",
    "    def __init__(self, c_out, pool, res = False, pooling=False):\n",
    "        super().__init__()\n",
    "        self.conv_bn = ConvBN(c_out)\n",
    "        self.pool = pool\n",
    "        self.res = res\n",
    "        self.pooling = pooling\n",
    "        if self.res:\n",
    "            self.res1 = ConvBN(c_out)\n",
    "            self.res2 = ConvBN(c_out)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.pooling:\n",
    "            h = self.pool(self.conv_bn(inputs))\n",
    "        else:\n",
    "            h = self.conv_bn(inputs)\n",
    "        \n",
    "        if self.res:\n",
    "            residual = self.res2(self.res1(h))\n",
    "            h = h + residual\n",
    "        return h\n",
    "    \n",
    "    \n",
    "class DavidNet(tf.keras.Model):\n",
    "    def __init__(self, c=64, weight=0.125):\n",
    "        super().__init__()\n",
    "        pool = tf.keras.layers.MaxPooling2D()\n",
    "        self.init_conv_bn = ConvBN(c)\n",
    "        self.blk1 = ResBlk(c*2, pool, res = True, pooling = True)\n",
    "        self.blk2 = ResBlk(c*4, pool, pooling = True)\n",
    "        self.blk3 = ResBlk(c*8, pool, res = True, pooling = False)\n",
    "        self.pool = tf.keras.layers.GlobalMaxPool2D()\n",
    "        self.linear = tf.keras.layers.Dense(10, kernel_initializer=init_pytorch, use_bias=False)\n",
    "        self.weight = weight\n",
    "\n",
    "    def call(self, x, y):\n",
    "        h = self.pool(self.blk3(self.blk2(self.blk1(self.init_conv_bn(x)))))\n",
    "        h = self.linear(h) * self.weight\n",
    "        ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=h, labels=y)\n",
    "        loss = tf.reduce_sum(ce)\n",
    "        correct = tf.reduce_sum(tf.cast(tf.math.equal(tf.argmax(h, axis = 1), y), tf.float32))\n",
    "        return loss, correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "colab_type": "code",
    "id": "2-rBodFhQeNZ",
    "outputId": "44767619-e69d-4225-b491-d096a55315e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "model = DavidNet(weight=0.00125)\n",
    "batches_per_epoch = len_train//BATCH_SIZE + 1\n",
    "\n",
    "\n",
    "\n",
    "lr_schedule = lambda t: np.interp([t], [0, (EPOCHS+1)//5, EPOCHS], [0, LEARNING_RATE, 0])[0]\n",
    "# lr_schedule = lambda t: np.interp([t], [0, (EPOCHS+1)//4, EPOCHS], [0.001, LEARNING_RATE, 0.00001])[0]\n",
    "global_step = tf.train.get_or_create_global_step()\n",
    "lr_func = lambda: lr_schedule(global_step/batches_per_epoch)\n",
    "\n",
    "\n",
    "opt = tf.train.MomentumOptimizer(lr_func, momentum=MOMENTUM, use_nesterov=True)\n",
    "data_aug = lambda x, y: (tf.image.random_flip_left_right(tf.random_crop(x, [32, 32, 3])), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 657
    },
    "colab_type": "code",
    "id": "HwZTCT7lxTEw",
    "outputId": "8bcf2b3d-4952-4c4f-e9fd-6e3b4429d14c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 1 lr: 0.0800 | train loss: 2.0199 train acc: 0.207 val loss: 1.8853 val acc: 0.285 epoch time: 27.48 time: 27.48\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 2 lr: 0.1600 | train loss: 1.3639 train acc: 0.493 val loss: 2.4433 val acc: 0.431 epoch time: 21.79 time: 49.28\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 3 lr: 0.2400 | train loss: 0.8520 train acc: 0.697 val loss: 1.2456 val acc: 0.621 epoch time: 22.02 time: 71.30\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 4 lr: 0.3200 | train loss: 0.6540 train acc: 0.772 val loss: 0.8335 val acc: 0.727 epoch time: 21.94 time: 93.23\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 5 lr: 0.4000 | train loss: 0.5751 train acc: 0.800 val loss: 0.9356 val acc: 0.725 epoch time: 21.83 time: 115.07\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 6 lr: 0.3789 | train loss: 0.4918 train acc: 0.831 val loss: 0.7413 val acc: 0.761 epoch time: 21.84 time: 136.91\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 7 lr: 0.3579 | train loss: 0.4194 train acc: 0.856 val loss: 0.5111 val acc: 0.832 epoch time: 21.92 time: 158.83\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 8 lr: 0.3368 | train loss: 0.3588 train acc: 0.876 val loss: 0.4322 val acc: 0.854 epoch time: 21.74 time: 180.57\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 9 lr: 0.3158 | train loss: 0.3140 train acc: 0.891 val loss: 0.4628 val acc: 0.853 epoch time: 21.71 time: 202.27\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 10 lr: 0.2947 | train loss: 0.2771 train acc: 0.904 val loss: 0.4168 val acc: 0.865 epoch time: 21.72 time: 223.99\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 11 lr: 0.2737 | train loss: 0.2386 train acc: 0.916 val loss: 0.3954 val acc: 0.870 epoch time: 21.88 time: 245.87\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 12 lr: 0.2526 | train loss: 0.2042 train acc: 0.928 val loss: 0.3951 val acc: 0.871 epoch time: 21.91 time: 267.78\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 13 lr: 0.2316 | train loss: 0.1771 train acc: 0.937 val loss: 0.3661 val acc: 0.885 epoch time: 21.83 time: 289.61\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 14 lr: 0.2105 | train loss: 0.1520 train acc: 0.946 val loss: 0.4304 val acc: 0.870 epoch time: 21.81 time: 311.42\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 15 lr: 0.1895 | train loss: 0.1281 train acc: 0.955 val loss: 0.4325 val acc: 0.874 epoch time: 22.00 time: 333.42\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 16 lr: 0.1684 | train loss: 0.1065 train acc: 0.962 val loss: 0.3542 val acc: 0.896 epoch time: 21.75 time: 355.17\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 17 lr: 0.1474 | train loss: 0.0845 train acc: 0.970 val loss: 0.3851 val acc: 0.893 epoch time: 21.88 time: 377.05\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 18 lr: 0.1263 | train loss: 0.0724 train acc: 0.975 val loss: 0.3772 val acc: 0.896 epoch time: 22.06 time: 399.11\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 19 lr: 0.1053 | train loss: 0.0565 train acc: 0.981 val loss: 0.3688 val acc: 0.906 epoch time: 21.90 time: 421.02\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 20 lr: 0.0842 | train loss: 0.0434 train acc: 0.985 val loss: 0.3710 val acc: 0.904 epoch time: 21.93 time: 442.94\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 21 lr: 0.0632 | train loss: 0.0337 train acc: 0.989 val loss: 0.3480 val acc: 0.912 epoch time: 21.74 time: 464.69\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 22 lr: 0.0421 | train loss: 0.0268 train acc: 0.991 val loss: 0.3400 val acc: 0.918 epoch time: 21.90 time: 486.59\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 23 lr: 0.0211 | train loss: 0.0200 train acc: 0.994 val loss: 0.3468 val acc: 0.916 epoch time: 21.87 time: 508.46\n",
      "----------------------------------------------------------------------------------------------------\n",
      "epoch = 24 lr: 0.0000 | train loss: 0.0177 train acc: 0.995 val loss: 0.3349 val acc: 0.919 epoch time: 22.00 time: 530.46\n"
     ]
    }
   ],
   "source": [
    "print(gc.collect())\n",
    "t = time.time()\n",
    "t_last = time.time()\n",
    "test_set = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss = test_loss = train_acc = test_acc = 0.0\n",
    "    train_set = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(data_aug).shuffle(len_train).batch(BATCH_SIZE).prefetch(1)\n",
    "\n",
    "    tf.keras.backend.set_learning_phase(1)\n",
    "    for (x, y) in train_set:\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss, correct = model(x, y)\n",
    "\n",
    "        var = model.trainable_variables\n",
    "        grads = tape.gradient(loss, var)\n",
    "        for g, v in zip(grads, var):\n",
    "            g += v * WEIGHT_DECAY * BATCH_SIZE\n",
    "        opt.apply_gradients(zip(grads, var), global_step=global_step)\n",
    "\n",
    "        train_loss += loss.numpy()\n",
    "        train_acc += correct.numpy()\n",
    "\n",
    "    tf.keras.backend.set_learning_phase(0)\n",
    "    for (x, y) in test_set:\n",
    "        loss, correct = model(x, y)\n",
    "        test_loss += loss.numpy()\n",
    "        test_acc += correct.numpy()\n",
    "    t2 = time.time()\n",
    "    epoch_time = t2 - t_last\n",
    "    t_last = t2\n",
    "\n",
    "    print(\"-\"*100)\n",
    "    print(\"epoch = %s\"%(epoch+1),'lr: %.4f' % (lr_schedule(epoch+1)), '| train loss: %.4f' %(train_loss / len_train), 'train acc: %.3f' % (train_acc / len_train), 'val loss: %.4f' % (test_loss / len_test), 'val acc: %.3f' %(test_acc / len_test),\"epoch time: %.2f\"%(epoch_time), 'time: %.2f'%(t2 - t))\n",
    "  \n",
    "  # 92.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnLeh0rNLmVc"
   },
   "outputs": [],
   "source": [
    "# Batching code before or after map code.\n",
    "\n",
    "# Dropout\n",
    "# OneCycleLR\n",
    "# Cutout\n",
    "\n",
    "\n",
    "# Big ideas\n",
    "# Use Resnet with a highway network like mode with weights for residual, Penalize the weight for residual for its distance from 1.\n",
    "# Instead of L2 penalization of kernel weights use a Penalization which treats distance from 1/fan-in of weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "DavidNet.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
